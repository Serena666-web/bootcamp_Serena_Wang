{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d43c735-8918-4b69-869f-7c15da8adb15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyarrow\n",
      "  Downloading pyarrow-21.0.0-cp313-cp313-macosx_12_0_arm64.whl.metadata (3.3 kB)\n",
      "Downloading pyarrow-21.0.0-cp313-cp313-macosx_12_0_arm64.whl (31.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.2/31.2 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyarrow\n",
      "Successfully installed pyarrow-21.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c86bfc4d-df57-4d30-876a-c241c7263ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: /Users/wangyuhan/bootcamp_Serena_Wang/homework/homework05\n",
      "DATA_DIR_RAW: /Users/wangyuhan/bootcamp_Serena_Wang/homework/homework05/data/raw\n",
      "DATA_DIR_PROCESSED: /Users/wangyuhan/bootcamp_Serena_Wang/homework/homework05/data/processed\n",
      "Using DataFrame with shape: (5, 3)\n",
      "Critical columns for dtype check: ['id', 'value']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>value</th>\n",
       "      <th>stamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2025-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>12.5</td>\n",
       "      <td>2025-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9.9</td>\n",
       "      <td>2025-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>11.2</td>\n",
       "      <td>2025-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>13.7</td>\n",
       "      <td>2025-01-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  value      stamp\n",
       "0   1   10.0 2025-01-01\n",
       "1   2   12.5 2025-01-02\n",
       "2   3    9.9 2025-01-03\n",
       "3   4   11.2 2025-01-04\n",
       "4   5   13.7 2025-01-05"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "CWD = Path.cwd()\n",
    "PROJECT_ROOT = CWD.parent if CWD.name == \"notebooks\" else CWD\n",
    "env_path = PROJECT_ROOT / \".env\"\n",
    "load_dotenv(env_path, override=False)\n",
    "RAW_REL = os.getenv(\"DATA_DIR_RAW\", \"data/raw\")\n",
    "PROC_REL = os.getenv(\"DATA_DIR_PROCESSED\", \"data/processed\")\n",
    "\n",
    "DATA_DIR_RAW = PROJECT_ROOT / RAW_REL\n",
    "DATA_DIR_PROCESSED = PROJECT_ROOT / PROC_REL\n",
    "DATA_DIR_RAW.mkdir(parents=True, exist_ok=True)\n",
    "DATA_DIR_PROCESSED.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"DATA_DIR_RAW:\", DATA_DIR_RAW)\n",
    "print(\"DATA_DIR_PROCESSED:\", DATA_DIR_PROCESSED)\n",
    "\n",
    "def _ensure_parent(p: Path) -> Path:\n",
    "    p.parent.mkdir(parents=True, exist_ok=True)\n",
    "    return p\n",
    "\n",
    "if \"df_api\" in globals() and isinstance(df_api, pd.DataFrame) and not df_api.empty:\n",
    "    df = df_api.copy()\n",
    "    critical_cols = [\"date\", \"adj_close\"] if set([\"date\",\"adj_close\"]).issubset(df.columns) else list(df.columns[:2])\n",
    "else:\n",
    "    df = pd.DataFrame({\n",
    "        \"id\": range(1, 6),\n",
    "        \"value\": [10.0, 12.5, 9.9, 11.2, 13.7],\n",
    "        \"stamp\": pd.date_range(\"2025-01-01\", periods=5, freq=\"D\")\n",
    "    })\n",
    "    critical_cols = [\"id\", \"value\"]  # expected dtypes: int/float\n",
    "\n",
    "print(\"Using DataFrame with shape:\", df.shape)\n",
    "print(\"Critical columns for dtype check:\", critical_cols)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3e2abef-693b-4c24-a67d-51e04e4ceabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved CSV to /Users/wangyuhan/bootcamp_Serena_Wang/homework/homework05/data/raw/example_dataset.csv\n",
      "Saved Parquet to /Users/wangyuhan/bootcamp_Serena_Wang/homework/homework05/data/processed/example_dataset.parquet\n"
     ]
    }
   ],
   "source": [
    "def write_df(df: pd.DataFrame, path: Path) -> Path:\n",
    "    path = Path(path)\n",
    "    _ensure_parent(path)\n",
    "    suf = path.suffix.lower()\n",
    "    if suf == \".csv\":\n",
    "        df.to_csv(path, index=False)\n",
    "    elif suf == \".parquet\":\n",
    "        try:\n",
    "            # prefer pyarrow; pandas will raise if no engine is available\n",
    "            df.to_parquet(path, index=False)\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(\n",
    "                \"Failed to write Parquet. Install a Parquet engine, e.g.: \"\n",
    "                \"`pip install pyarrow` or `pip install fastparquet`.\\n\"\n",
    "                f\"Original error: {e}\"\n",
    "            )\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file suffix: {suf} (use .csv or .parquet)\")\n",
    "    return path\n",
    "def read_df(path: Path) -> pd.DataFrame:\n",
    "    path = Path(path)\n",
    "    suf = path.suffix.lower()\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Missing file: {path}\")\n",
    "    if suf == \".csv\":\n",
    "        return pd.read_csv(path)\n",
    "    elif suf == \".parquet\":\n",
    "        try:\n",
    "            return pd.read_parquet(path)\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(\n",
    "                \"Failed to read Parquet. Install a Parquet engine, e.g.: \"\n",
    "                \"`pip install pyarrow` or `pip install fastparquet`.\\n\"\n",
    "                f\"Original error: {e}\"\n",
    "            )\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file suffix: {suf} (use .csv or .parquet)\")\n",
    "\n",
    "# Save in two format\n",
    "raw_csv_path = DATA_DIR_RAW / \"example_dataset.csv\"\n",
    "proc_parquet_path = DATA_DIR_PROCESSED / \"example_dataset.parquet\"\n",
    "\n",
    "p1 = write_df(df, raw_csv_path)\n",
    "p2 = write_df(df, proc_parquet_path)\n",
    "\n",
    "print(\"Saved CSV to\", p1)\n",
    "print(\"Saved Parquet to\", p2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c186307-e453-48d9-9da7-d7196c8b282f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>value</th>\n",
       "      <th>stamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2025-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>12.5</td>\n",
       "      <td>2025-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9.9</td>\n",
       "      <td>2025-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>11.2</td>\n",
       "      <td>2025-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>13.7</td>\n",
       "      <td>2025-01-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  value      stamp\n",
       "0   1   10.0 2025-01-01\n",
       "1   2   12.5 2025-01-02\n",
       "2   3    9.9 2025-01-03\n",
       "3   4   11.2 2025-01-04\n",
       "4   5   13.7 2025-01-05"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "p = Path(\"/Users/wangyuhan/bootcamp_Serena_Wang/homework/homework05/data/processed/example_dataset.parquet\")\n",
    "\n",
    "# If you don't have a Parquet engine yet, install one once:\n",
    "# %pip install pyarrow   # or: %pip install fastparquet\n",
    "\n",
    "df = pd.read_parquet(p)            # or: pd.read_parquet(p, engine=\"pyarrow\")\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac15d652-6748-4755-b9f6-d9430010aa6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV shape: (5, 3) | Parquet shape: (5, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>check</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shape_match_csv</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shape_match_parquet</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dtype_id_orig</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dtype_id_csv</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dtype_id_parquet</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dtype_equal_csv_id</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dtype_equal_parquet_id</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dtype_value_orig</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dtype_value_csv</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dtype_value_parquet</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dtype_equal_csv_value</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>dtype_equal_parquet_value</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        check    value\n",
       "0             shape_match_csv     True\n",
       "1         shape_match_parquet     True\n",
       "2               dtype_id_orig    int64\n",
       "3                dtype_id_csv    int64\n",
       "4            dtype_id_parquet    int64\n",
       "5          dtype_equal_csv_id     True\n",
       "6      dtype_equal_parquet_id     True\n",
       "7            dtype_value_orig  float64\n",
       "8             dtype_value_csv  float64\n",
       "9         dtype_value_parquet  float64\n",
       "10      dtype_equal_csv_value     True\n",
       "11  dtype_equal_parquet_value     True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reload and Validation\n",
    "\n",
    "df_csv = read_df(raw_csv_path)\n",
    "df_parq = read_df(proc_parquet_path)\n",
    "\n",
    "print(\"CSV shape:\", df_csv.shape, \"| Parquet shape:\", df_parq.shape)\n",
    "\n",
    "def validate_storage_roundtrip(df_original: pd.DataFrame,\n",
    "                               df_csv: pd.DataFrame,\n",
    "                               df_parquet: pd.DataFrame,\n",
    "                               critical_cols: list[str]) -> pd.DataFrame:\n",
    "    report = []\n",
    "    # Shapes\n",
    "    report.append((\"shape_match_csv\", df_original.shape == df_csv.shape))\n",
    "    report.append((\"shape_match_parquet\", df_original.shape == df_parquet.shape))\n",
    "\n",
    "    # Dtype expectations: use original df as truth\n",
    "    for col in critical_cols:\n",
    "        if col not in df_original.columns:\n",
    "            report.append((f\"dtype_{col}_present_in_original\", False))\n",
    "            continue\n",
    "        orig_kind = str(df_original[col].dtype)\n",
    "        csv_kind = str(df_csv[col].dtype) if col in df_csv.columns else \"MISSING\"\n",
    "        pq_kind  = str(df_parquet[col].dtype) if col in df_parquet.columns else \"MISSING\"\n",
    "        report.append((f\"dtype_{col}_orig\", orig_kind))\n",
    "        report.append((f\"dtype_{col}_csv\", csv_kind))\n",
    "        report.append((f\"dtype_{col}_parquet\", pq_kind))\n",
    "        report.append((f\"dtype_equal_csv_{col}\", (csv_kind == orig_kind)))\n",
    "        report.append((f\"dtype_equal_parquet_{col}\", (pq_kind == orig_kind)))\n",
    "\n",
    "    # Assemble DataFrame\n",
    "    return pd.DataFrame(report, columns=[\"check\", \"value\"])\n",
    "\n",
    "validation_report = validate_storage_roundtrip(df, df_csv, df_parq, critical_cols)\n",
    "validation_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0bc7a2c0-0fb4-4cb8-ba25-75bd2624053f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parquet read/write OK: /Users/wangyuhan/bootcamp_Serena_Wang/homework/homework05/data/processed/engine_check.parquet\n"
     ]
    }
   ],
   "source": [
    "# Refactor\n",
    "try:\n",
    "    tmp = DATA_DIR_PROCESSED / \"engine_check.parquet\"\n",
    "    write_df(df.head(1), tmp)\n",
    "    _ = read_df(tmp)\n",
    "    print(\"Parquet read/write OK:\", tmp)\n",
    "    tmp.unlink(missing_ok=True)\n",
    "except RuntimeError as e:\n",
    "    print(\"As expected, Parquet engine missing message:\\n\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429b404a-5622-4a60-868d-8145b9e8e211",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
